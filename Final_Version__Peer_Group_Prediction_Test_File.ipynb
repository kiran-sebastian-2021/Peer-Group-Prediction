{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Topic - Peer Group Prediction\n",
        "\n",
        "Details about the data:\n",
        "Human face image files are available, all the images are split based on the ages. 6 age groups are available, it varies from 20 to 49. In each age group multiple image files are available.\n"
      ],
      "metadata": {
        "id": "KpM5hk3RgcTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report,r2_score\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "o7N7ZrvfgkAJ"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read testing images and preprocess the data and split the features and the targets"
      ],
      "metadata": {
        "id": "vQrpcbLWrE0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_test_data():\n",
        "  # set the path of the folder where the images stored\n",
        "    data_dir = \"/content/drive/MyDrive/AGE DATASET/final_test_data/\"\n",
        "    # set the list of age categories available in the folder\n",
        "    categories = [\"2024\",\"2529\",\"3034\",\"3539\",\"4044\",\"4549\"]\n",
        "    # set an image size\n",
        "    IMG_SIZE = 50\n",
        "    \n",
        "    testing_data = []\n",
        "    # function to read all the images and extract the testing images and corresponding classes\n",
        "    def generate_testing_data():\n",
        "        # iterate through all the age folder and through each image\n",
        "        for item_ in categories:\n",
        "          # create location to individual images based on the ages  \n",
        "            path = os.path.join(data_dir,item_)  \n",
        "            # get the classification  based each age group\n",
        "            class_num = categories.index(item_)  \n",
        "            # iterate over each image per age folder\n",
        "            for img in (os.listdir(path)): \n",
        "                try:\n",
        "                  # reading and coverting the images\n",
        "                    img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
        "                    # resize to normalize data size\n",
        "                    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  \n",
        "                    # add this to our training_data\n",
        "                    testing_data.append([new_array, class_num])  \n",
        "                #to avoid unexpected error\n",
        "                except Exception as e:  \n",
        "                    pass\n",
        "\n",
        "    generate_testing_data()\n",
        "    print(len(testing_data))\n",
        "        \n",
        "    feature = []\n",
        "    target = []\n",
        "    # spli the set of features and targets\n",
        "    for features,label in testing_data:\n",
        "        feature.append(features)\n",
        "        target.append(label)\n",
        "    # convert the features and targets into numpy array format\n",
        "    feature = np.array(feature).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    target = np.array(target)\n",
        "    # normalizing the test features\n",
        "    X_test = feature/255\n",
        "    \n",
        "    # Print the shape of x_test again.\n",
        "    print(X_test.shape)\n",
        "    #assigning the target values into another variable\n",
        "    y_test = target\n",
        "    # Print the shape of y_test again\n",
        "    print(y_test.shape)\n",
        "\n",
        "    # Your code to print shape of y_test\n",
        "    print(y_test.shape)    \n",
        "    # Print shape of y_test [0]\n",
        "    print(y_test[0].shape)\n",
        "    \n",
        "    # Your code to use to_categorical to convert integers to numbers. Assign the new array to the variable y_test\n",
        "    Y_test = to_categorical(y_test)\n",
        "    # saving the actual test data for further reference\n",
        "    np.savetxt(\"5batch_test_target.csv\", Y_test, delimiter=\",\")\n",
        "\n",
        "        \n",
        "    # Print shape of the array y_cat_train\n",
        "    print(Y_test.shape)\n",
        "    # returning the set of testing features and targets\n",
        "    return X_test, Y_test\n"
      ],
      "metadata": {
        "id": "6h_w3TGbqv3Q"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing model"
      ],
      "metadata": {
        "id": "IvqpgNbpq_8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(X_test, Y_test):\n",
        "   # load the saved model\n",
        "    CNN_model = load_model('/content/5batch_age_model_v2_.h5')\n",
        "    print('Testing Started \\n\\n\\n')\n",
        "\n",
        "    # CNN_model.evaluate(X_test, Y_test, verbose=0)\n",
        "    predictions_prob = CNN_model.predict(X_test)\n",
        "    predictions = predictions_prob.argmax(axis=-1)\n",
        "       \n",
        "    # print('Exact prediction',accuracy_cnt)\n",
        "    score = CNN_model.evaluate(X_test, Y_test, verbose=0)\n",
        "    # print(\"Test Score: \", score[0])\n",
        "    print('Test loss:', score[0])\n",
        "    print(\"Accuracy: \", score[1]*100)\n",
        "\n",
        "    Y_test = np.argmax(Y_test, axis=-1)\n",
        "    predictions_prob = np.argmax(predictions_prob, axis=-1)\n",
        "    print('\\n\\n')\n",
        "\n",
        "    np.savetxt(\"5batch_test_target.csv\", Y_test, delimiter=\",\")\n",
        "    np.savetxt(\"5batch_predicted_target.csv\", predictions_prob, delimiter=\",\")\n",
        "\n",
        "    print('******classification report******')\n",
        "    print(classification_report(Y_test, predictions_prob))\n",
        "    print('__________________________')\n",
        "    # displays the confusion matrix\n",
        "    print('\\nConfusion Matrix')\n",
        "    print('__________________________')\n",
        "    y_actual = pd.Series(Y_test, name='Actual')\n",
        "    y_predicted = pd.Series(predictions_prob, name='Predicted')\n",
        "    plot_confusion_matrix = pd.crosstab(y_actual, y_predicted)\n",
        "    print(plot_confusion_matrix)\n",
        "    \n",
        "    # alternate function to plot the confusion matrix\n",
        "    # print(confusion_matrix(Y_test, predictions_prob))\n",
        "\n",
        "    return predictions_prob, predictions\n"
      ],
      "metadata": {
        "id": "c0a2nSzdqwGF"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    X_test, Y_test = preprocess_test_data()\n",
        "    results,pred_ = test_model(X_test, Y_test)\n"
      ],
      "metadata": {
        "id": "VEm86goPOdrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a133d4-0b99-4651-9b01-c49a501129c9"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1800\n",
            "(1800, 50, 50, 1)\n",
            "(1800,)\n",
            "(1800,)\n",
            "()\n",
            "(1800, 6)\n",
            "Testing Started \n",
            "\n",
            "\n",
            "\n",
            "57/57 [==============================] - 1s 18ms/step\n",
            "Test loss: 1.927790880203247\n",
            "Accuracy:  72.83333539962769\n",
            "\n",
            "\n",
            "\n",
            "******classification report******\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.78      0.72       300\n",
            "           1       0.76      0.71      0.74       300\n",
            "           2       0.72      0.76      0.74       300\n",
            "           3       0.73      0.66      0.69       300\n",
            "           4       0.80      0.69      0.74       300\n",
            "           5       0.70      0.77      0.73       300\n",
            "\n",
            "    accuracy                           0.73      1800\n",
            "   macro avg       0.73      0.73      0.73      1800\n",
            "weighted avg       0.73      0.73      0.73      1800\n",
            "\n",
            "__________________________\n",
            "\n",
            "Confusion Matrix\n",
            "__________________________\n",
            "Predicted    0    1    2    3    4    5\n",
            "Actual                                 \n",
            "0          233   15   18   12    8   14\n",
            "1           28  214   16   13   10   19\n",
            "2           23   17  228   12    7   13\n",
            "3           28    9   24  199   14   26\n",
            "4           18   16   14   19  207   26\n",
            "5           15   10   15   18   12  230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fm_2RRAeOdtn"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W0-bMDscOdwA"
      },
      "execution_count": 86,
      "outputs": []
    }
  ]
}