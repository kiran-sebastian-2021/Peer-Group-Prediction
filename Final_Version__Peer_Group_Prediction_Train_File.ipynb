{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpM5hk3RgcTz"
      },
      "source": [
        "Topic - Peer Group Prediction\n",
        "\n",
        "Details about the data:\n",
        "Human face image files are available, all the images are split based on the ages. 6 age groups are available, it varies from 20 to 49. In each age group multiple image files are available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7N7ZrvfgkAJ"
      },
      "outputs": [],
      "source": [
        "# importing the libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow. keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQrpcbLWrE0M"
      },
      "source": [
        "Read training images and preprocess the data and split the features and the targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6h_w3TGbqv3Q"
      },
      "outputs": [],
      "source": [
        "def preprocess_train_data():\n",
        "   # assigning the path and list of age categories\n",
        "   # set the path of the folder where the images stored\n",
        "    data_dir = \"/content/drive/MyDrive/AGE DATASET/train_5batch_modified/\"\n",
        "   # set the list of age categories available in the folder\n",
        "    categories = [\"2024\",\"2529\",\"3034\",\"3539\",\"4044\",\"4549\"]\n",
        "   \n",
        "   # analyze the images\n",
        "    for item_ in categories:\n",
        "      # assigning the location of the images to a variable , 6 classes\n",
        "        path = os.path.join(data_dir, item_)  \n",
        "        # iterate over each images, considering all the age groups\n",
        "        for img in os.listdir(path):  \n",
        "          # read one by one image\n",
        "            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)  # convert to array\n",
        "            # plot the image\n",
        "            # plt.imshow(img_array, cmap='gray')  \n",
        "            # plt.show()  # displays the last image!\n",
        "            break  # executing one at a time\n",
        "        break  #break the for loop \n",
        "    # checking the array shape\n",
        "    print(img_array.shape) #(128, 128)\n",
        "    # set an image size\n",
        "    IMG_SIZE = 50\n",
        "    #initialize new array to keep all the training data\n",
        "    training_data = []\n",
        "    \n",
        "    # function to read all the images and extract the training images and corresponding classes\n",
        "    def generate_training_data():\n",
        "      # iterate through all the age folder and through each image\n",
        "        for item_ in categories:  \n",
        "          # access the location to individual images based on the age group\n",
        "            path = os.path.join(data_dir,item_) \n",
        "            # get the list of available classes based each age group \n",
        "            class_num = categories.index(item_)  \n",
        "            \n",
        "            # iterate over each image per age folder\n",
        "            for img in (os.listdir(path)):  \n",
        "                try:\n",
        "                    # read one by one images and convert it into the grayscale format, which is an array\n",
        "                    img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  \n",
        "                    # resize the image; means it helps to normalize data size\n",
        "                    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  \n",
        "                    # adding the extracted trained data and corresponding classes to a list\n",
        "                    training_data.append([new_array, class_num])  \n",
        "                # skip the errors, if there is any possibility to occur\n",
        "                except Exception as e:  \n",
        "                    pass\n",
        "\n",
        "    generate_training_data()\n",
        "    #checking the total size of the training data\n",
        "    print(len(training_data))\n",
        "        \n",
        "    #initialize an empty list to add the list of training features\n",
        "    feature = []\n",
        "    #initialize an empty list to add the list of training targets\n",
        "    target = []\n",
        "    \n",
        "    # iterating through the set of training features and targets\n",
        "    for features,label in training_data:\n",
        "        # extracted feature from the training_data will be added to the 'feature' variable\n",
        "        feature.append(features)\n",
        "        # extracted target from the training_data will be added to the 'target' variable\n",
        "        target.append(label)\n",
        "\n",
        "    # convert the set of features into a numpy array and reshape it\n",
        "    feature = np.array(feature).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    # convert the set of targets into a numpy array\n",
        "    target = np.array(target)\n",
        "    # normalize the set of training features\n",
        "    X_train = feature/255\n",
        "    \n",
        "    # display the shape of X_train\n",
        "    print(X_train.shape)\n",
        "    # assign the target into another variable 'Y_train'\n",
        "    Y_train = target\n",
        "    # display the shape of Y_train\n",
        "    print(Y_train.shape)\n",
        "    # targets are integers. so, converting it into binary digits using the function 'to_categorical' and assign it to the new array 'Y_train'\n",
        "    Y_train = to_categorical(Y_train)\n",
        "        \n",
        "    # display the shape of Y_train\n",
        "    print(Y_train.shape)\n",
        "    # return the set of training features and targets\n",
        "    return X_train, Y_train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvqpgNbpq_8F"
      },
      "source": [
        "Building the training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0a2nSzdqwGF"
      },
      "outputs": [],
      "source": [
        "# build the training model\n",
        "# passing the training features and targets to the 'build_train_model' function\n",
        "def build_train_model(X_train, y_train):\n",
        "    # initializing the model\n",
        "    CNN_model = Sequential()\n",
        "    # adding conv2D layer and parameters, to extract the features\n",
        "    CNN_model.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(50,50,1), activation='relu',))\n",
        "    # adding maxpool2D layer , to extract the improtant features\n",
        "    CNN_model.add(MaxPool2D(pool_size=(2, 2)))   \n",
        "    # adding flatten layer, used to flatten the data\n",
        "    CNN_model.add(Flatten())\n",
        "    # adding dropout layer, to reduce the overfitting \n",
        "    CNN_model.add(Dropout(0.25))\n",
        "    # adding 1st dense layer,fully connected layer\n",
        "    CNN_model.add(Dense(128, activation='relu'))\n",
        "    # CNN_model.add(Dense(84, activation='relu'))\n",
        "    # CNN_model.add(Dropout(0.25))\n",
        "    # CNN_model.add(Dense(72, activation='relu'))\n",
        "    # CNN_model.add(Dropout(0.25))\n",
        "    # CNN_model.add(Dense(56, activation='relu'))\n",
        "   \n",
        "    # adding 2nd dense layer\n",
        "    CNN_model.add(Dense(64, activation='relu'))\n",
        "    # CNN_model.add(Dense(32, activation='relu'))\n",
        "    # adding final dense layer, gives the final results\n",
        "    CNN_model.add(Dense(6, activation='softmax')) \n",
        "    print('CNN Model details \\n\\n\\n')\n",
        "    # display the model summary\n",
        "    CNN_model.summary()\n",
        "    # stops when loss function update become small\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "    #code to compile the models (model.compile). Use 'categorical cross entropy as the loss function'\n",
        "    CNN_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    print('Training Started \\n\\n\\n')\n",
        "\n",
        "    #fitting/training the CNN model, using additional parameter -  callbacks = [early_stop] to enable early stopping.\n",
        "    CNN_model.fit(X_train, y_train, epochs=30, batch_size=10,callbacks = [early_stop])   \n",
        "    print('Training Completed \\n\\n\\n')\n",
        "    CNN_model.save('5batch_age_model_v2_.h5')  # creates a HDF5 file '5batch_age_model_v2_.h5'\n",
        "    # losses = pd.DataFrame(CNN_model.history.history)\n",
        "    return CNN_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEm86goPOdrO",
        "outputId": "2067f61a-075c-4fc9-8fe5-4543c9cd970e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 128)\n",
            "26036\n",
            "(26036, 50, 50, 1)\n",
            "(26036,)\n",
            "(26036, 6)\n",
            "CNN Model details \n",
            "\n",
            "\n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 47, 47, 32)        544       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 23, 23, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16928)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16928)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               2166912   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,176,102\n",
            "Trainable params: 2,176,102\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training Started \n",
            "\n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 1.7687 - accuracy: 0.2213"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 122s 46ms/step - loss: 1.7687 - accuracy: 0.2213\n",
            "Epoch 2/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 1.7352 - accuracy: 0.2477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 117s 45ms/step - loss: 1.7352 - accuracy: 0.2477\n",
            "Epoch 3/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 1.6960 - accuracy: 0.2726"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 118s 45ms/step - loss: 1.6960 - accuracy: 0.2726\n",
            "Epoch 4/30\n",
            "2603/2604 [============================>.] - ETA: 0s - loss: 1.6363 - accuracy: 0.3088"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 118s 45ms/step - loss: 1.6363 - accuracy: 0.3088\n",
            "Epoch 5/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 1.5291 - accuracy: 0.3696"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 116s 45ms/step - loss: 1.5291 - accuracy: 0.3696\n",
            "Epoch 6/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 1.3692 - accuracy: 0.4495"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 122s 47ms/step - loss: 1.3692 - accuracy: 0.4495\n",
            "Epoch 7/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 1.1787 - accuracy: 0.5371"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 122s 47ms/step - loss: 1.1787 - accuracy: 0.5371\n",
            "Epoch 8/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.9855 - accuracy: 0.6222"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 127s 49ms/step - loss: 0.9855 - accuracy: 0.6222\n",
            "Epoch 9/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.8187 - accuracy: 0.6936"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 131s 50ms/step - loss: 0.8187 - accuracy: 0.6936\n",
            "Epoch 10/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.6815 - accuracy: 0.7476"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 133s 51ms/step - loss: 0.6815 - accuracy: 0.7476\n",
            "Epoch 11/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.5764 - accuracy: 0.7925"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 129s 50ms/step - loss: 0.5764 - accuracy: 0.7925\n",
            "Epoch 12/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.4914 - accuracy: 0.8262"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 125s 48ms/step - loss: 0.4914 - accuracy: 0.8262\n",
            "Epoch 13/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.4274 - accuracy: 0.8505"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 134s 52ms/step - loss: 0.4274 - accuracy: 0.8505\n",
            "Epoch 14/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.3766 - accuracy: 0.8730"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 137s 53ms/step - loss: 0.3766 - accuracy: 0.8730\n",
            "Epoch 15/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.3455 - accuracy: 0.8858"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 134s 51ms/step - loss: 0.3455 - accuracy: 0.8858\n",
            "Epoch 16/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.3023 - accuracy: 0.9003"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 131s 50ms/step - loss: 0.3023 - accuracy: 0.9003\n",
            "Epoch 17/30\n",
            "2603/2604 [============================>.] - ETA: 0s - loss: 0.2843 - accuracy: 0.9070"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 130s 50ms/step - loss: 0.2843 - accuracy: 0.9069\n",
            "Epoch 18/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.2467 - accuracy: 0.9189"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 129s 49ms/step - loss: 0.2467 - accuracy: 0.9189\n",
            "Epoch 19/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.9208"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 130s 50ms/step - loss: 0.2500 - accuracy: 0.9208\n",
            "Epoch 20/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.2220 - accuracy: 0.9265"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 129s 50ms/step - loss: 0.2220 - accuracy: 0.9265\n",
            "Epoch 21/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.2120 - accuracy: 0.9317"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 124s 48ms/step - loss: 0.2120 - accuracy: 0.9317\n",
            "Epoch 22/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.1962 - accuracy: 0.9363"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 129s 49ms/step - loss: 0.1962 - accuracy: 0.9363\n",
            "Epoch 23/30\n",
            "2603/2604 [============================>.] - ETA: 0s - loss: 0.1866 - accuracy: 0.9415"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 127s 49ms/step - loss: 0.1866 - accuracy: 0.9415\n",
            "Epoch 24/30\n",
            "2603/2604 [============================>.] - ETA: 0s - loss: 0.1819 - accuracy: 0.9413"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 129s 49ms/step - loss: 0.1819 - accuracy: 0.9412\n",
            "Epoch 25/30\n",
            "2603/2604 [============================>.] - ETA: 0s - loss: 0.1642 - accuracy: 0.9471"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 127s 49ms/step - loss: 0.1642 - accuracy: 0.9472\n",
            "Epoch 26/30\n",
            "2603/2604 [============================>.] - ETA: 0s - loss: 0.1595 - accuracy: 0.9491"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 130s 50ms/step - loss: 0.1596 - accuracy: 0.9490\n",
            "Epoch 27/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.1553 - accuracy: 0.9508"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 133s 51ms/step - loss: 0.1553 - accuracy: 0.9508\n",
            "Epoch 28/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.1478 - accuracy: 0.9517"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 130s 50ms/step - loss: 0.1478 - accuracy: 0.9517\n",
            "Epoch 29/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.9519"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 129s 50ms/step - loss: 0.1525 - accuracy: 0.9519\n",
            "Epoch 30/30\n",
            "2604/2604 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.9558"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2604/2604 [==============================] - 132s 51ms/step - loss: 0.1421 - accuracy: 0.9558\n",
            "Training Completed \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    # preprocess the training images\n",
        "    X_train, Y_train = preprocess_train_data()\n",
        "    # building trained model\n",
        "    CNN_model = build_train_model(X_train, Y_train)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm_2RRAeOdtn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0-bMDscOdwA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}