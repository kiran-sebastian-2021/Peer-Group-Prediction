{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpM5hk3RgcTz"
      },
      "source": [
        "Topic - Peer Group Prediction\n",
        "\n",
        "Details about the data:\n",
        "Human face image files are available, all the images are split based on the ages. 6 age groups are available, it varies from 20 to 49. In each age group multiple image files are available.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow. keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n",
        "                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D,\\\n",
        "ZeroPadding2D, Convolution2D, ZeroPadding2D,AveragePooling2D\n",
        "from keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n"
      ],
      "metadata": {
        "id": "bPVWYGmKF5qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_train_data():\n",
        "   # assigning the path and list of age categories\n",
        "   # set the path of the folder where the images stored\n",
        "    data_dir = \"/content/drive/MyDrive/AGE DATASET/train_5batch_modified/\"\n",
        "   # set the list of age categories available in the folder\n",
        "    # categories = [\"2024\",\"2529\"]\n",
        "    categories = [\"2024\",\"2529\",\"3034\",\"3539\",\"4044\",\"4549\"]\n",
        "   \n",
        "   # analyze the images\n",
        "    for item_ in categories:\n",
        "      # assigning the location of the images to a variable , 6 classes\n",
        "        path = os.path.join(data_dir, item_)  \n",
        "        # iterate over each images, considering all the age groups\n",
        "        for img in os.listdir(path):  \n",
        "          # read one by one image\n",
        "            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)  # convert to array\n",
        "            # plot the image\n",
        "            # plt.imshow(img_array, cmap='gray')  \n",
        "            # plt.show()  # displays the last image!\n",
        "            break  # executing one at a time\n",
        "        break  #break the for loop \n",
        "    # checking the array shape\n",
        "    print(img_array.shape) #(128, 128)\n",
        "    # set an image size\n",
        "    IMG_SIZE = 50\n",
        "    #initialize new array to keep all the training data\n",
        "    training_data = []\n",
        "    \n",
        "    # function to read all the images and extract the training images and corresponding classes\n",
        "    def generate_training_data():\n",
        "      # iterate through all the age folder and through each image\n",
        "        for item_ in categories:  \n",
        "          # access the location to individual images based on the age group\n",
        "            path = os.path.join(data_dir,item_) \n",
        "            # get the list of available classes based each age group \n",
        "            class_num = categories.index(item_)  \n",
        "            \n",
        "            # iterate over each image per age folder\n",
        "            for img in (os.listdir(path)):  \n",
        "                try:\n",
        "                    # read one by one images and convert it into the grayscale format, which is an array\n",
        "                    img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  \n",
        "                    # resize the image; means it helps to normalize data size\n",
        "                    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  \n",
        "                    # adding the extracted trained data and corresponding classes to a list\n",
        "                    training_data.append([new_array, class_num])  \n",
        "                # skip the errors, if there is any possibility to occur\n",
        "                except Exception as e:  \n",
        "                    pass\n",
        "\n",
        "    generate_training_data()\n",
        "    #checking the total size of the training data\n",
        "    print(len(training_data))\n",
        "        \n",
        "    #initialize an empty list to add the list of training features\n",
        "    feature = []\n",
        "    #initialize an empty list to add the list of training targets\n",
        "    target = []\n",
        "    \n",
        "    # iterating through the set of training features and targets\n",
        "    for features,label in training_data:\n",
        "        # extracted feature from the training_data will be added to the 'feature' variable\n",
        "        feature.append(features)\n",
        "        # extracted target from the training_data will be added to the 'target' variable\n",
        "        target.append(label)\n",
        "\n",
        "    # convert the set of features into a numpy array and reshape it\n",
        "    feature = np.array(feature).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    # convert the set of targets into a numpy array\n",
        "    target = np.array(target)\n",
        "    # normalize the set of training features\n",
        "    X_train = feature/255\n",
        "    \n",
        "    # display the shape of X_train\n",
        "    print(X_train.shape)\n",
        "    # assign the target into another variable 'Y_train'\n",
        "    Y_train = target\n",
        "    # display the shape of Y_train\n",
        "    print(Y_train.shape)\n",
        "    # targets are integers. so, converting it into binary digits using the function 'to_categorical' and assign it to the new array 'Y_train'\n",
        "    Y_train = to_categorical(Y_train)\n",
        "        \n",
        "    # display the shape of Y_train\n",
        "    print(Y_train.shape)\n",
        "    # return the set of training features and targets\n",
        "    return X_train, Y_train\n"
      ],
      "metadata": {
        "id": "27gM56EAF5sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing the images\n",
        "X_train, Y_train = preprocess_train_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzaNlwyAF5vh",
        "outputId": "301f8652-0dd6-4206-a4d9-83b6b4495107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 128)\n",
            "26036\n",
            "(26036, 50, 50, 1)\n",
            "(26036,)\n",
            "(26036, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the number of images to be trained\n",
        "print(len(X_train))\n",
        "print(len(Y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_yFdH0nJKgx",
        "outputId": "3b517c3f-8703-4319-c19a-443b668a0bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26036\n",
            "26036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set the input shape of the image\n",
        "INPUT_SHAPE = (X_train.shape[1],X_train.shape[2],X_train.shape[3])\n",
        "\n",
        "#set early stopper and the checkpoint model (assign general parameters)\n",
        "Early_Stopper_fn = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=5,mode=\"min\")\n",
        "Checkpoint_Model = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\", save_best_only=True,\n",
        "                                                      save_weights_only=True, filepath=\"./modelcheck\")\n",
        "\n",
        "\n",
        "# for general\n",
        "# assigning optimzer into a variable\n",
        "optimizer_ = Adam()\n",
        "# assigning loss value into a variable\n",
        "loss_value_ = \"msle\" # msle stands for mean squared logarithmic error\n",
        "# assigning required metrics into a variable\n",
        "req_metrics = [\"accuracy\"]\n",
        "# assigning the list of target classes into a variable\n",
        "target_classes = 6\n",
        "\n",
        "\n",
        "# building a VGG16 Model\n",
        "# initializing the model\n",
        "VGG_Model = Sequential()\n",
        "# adding conv2D layer and parameters\n",
        "VGG_Model.add(Conv2D(32,(3,3),activation=\"relu\",input_shape=INPUT_SHAPE))\n",
        "# adding batch normalizing layer \n",
        "VGG_Model.add(BatchNormalization())\n",
        "# adding maxpool2D layer \n",
        "VGG_Model.add(MaxPooling2D((2,2)))\n",
        "# adding 2nd conv2D layer and parameters\n",
        "VGG_Model.add(Conv2D(64,(3,3),activation=\"relu\"))\n",
        "#add a drop out layer to reduce overfitting\n",
        "VGG_Model.add(Dropout(0.1))\n",
        "VGG_Model.add(MaxPooling2D((2,2)))\n",
        "VGG_Model.add(BatchNormalization())\n",
        "\n",
        "VGG_Model.add(Conv2D(128,(3,3),activation=\"relu\"))\n",
        "#add a drop out layer to reduce overfitting\n",
        "VGG_Model.add(Dropout(0.1))\n",
        "VGG_Model.add(MaxPooling2D((2,2)))\n",
        "VGG_Model.add(BatchNormalization())\n",
        "#flattening the layer\n",
        "VGG_Model.add(Flatten())\n",
        "\n",
        "VGG_Model.add(Dense(128,activation=\"relu\"))\n",
        "VGG_Model.add(BatchNormalization())\n",
        "#add a drop out layer to reduce overfitting\n",
        "VGG_Model.add(Dropout(0.4))\n",
        "VGG_Model.add(Dense(64,activation=\"relu\"))\n",
        "VGG_Model.add(BatchNormalization())\n",
        "#add a drop out layer to reduce overfitting\n",
        "VGG_Model.add(Dropout(0.3))\n",
        "#the outer most layer\n",
        "VGG_Model.add(Dense(target_classes,activation=\"softmax\"))\n",
        "\n",
        "#compiling the model\n",
        "VGG_Model.compile(optimizer=optimizer_,loss=loss_value_,metrics=req_metrics)\n",
        "# CNN_Model = Model.fit(X_train,Y_train, callbacks=[Early_Stopper_fn,Checkpoint_Model],\n",
        "#                       batch_size=12, epochs=50)\n",
        "\n",
        "# train the VGG model by setting early stopper\n",
        "VGG_Model_ = VGG_Model.fit(X_train, Y_train,  callbacks=[Early_Stopper_fn,Checkpoint_Model], epochs=30)   \n",
        "print('done')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrBgnTtdF51A",
        "outputId": "ba04f2ff-9070-4031-e4d1-e298e0a32c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.1766"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 174s 212ms/step - loss: 0.0790 - accuracy: 0.1766\n",
            "Epoch 2/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.1957"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 168s 206ms/step - loss: 0.0694 - accuracy: 0.1957\n",
            "Epoch 3/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.2107"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 161s 198ms/step - loss: 0.0680 - accuracy: 0.2107\n",
            "Epoch 4/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.2292"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 162s 199ms/step - loss: 0.0674 - accuracy: 0.2292\n",
            "Epoch 5/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.2477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 159s 195ms/step - loss: 0.0668 - accuracy: 0.2477\n",
            "Epoch 6/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.2582"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 161s 198ms/step - loss: 0.0664 - accuracy: 0.2582\n",
            "Epoch 7/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.2639"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 159s 196ms/step - loss: 0.0660 - accuracy: 0.2639\n",
            "Epoch 8/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.2726"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 161s 198ms/step - loss: 0.0656 - accuracy: 0.2726\n",
            "Epoch 9/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.2775"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 162s 199ms/step - loss: 0.0652 - accuracy: 0.2775\n",
            "Epoch 10/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.2893"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 159s 196ms/step - loss: 0.0648 - accuracy: 0.2893\n",
            "Epoch 11/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.2977"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 162s 200ms/step - loss: 0.0644 - accuracy: 0.2977\n",
            "Epoch 12/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.3037"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 162s 199ms/step - loss: 0.0642 - accuracy: 0.3037\n",
            "Epoch 13/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.3107"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 163s 201ms/step - loss: 0.0637 - accuracy: 0.3107\n",
            "Epoch 14/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.3202"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 161s 197ms/step - loss: 0.0634 - accuracy: 0.3202\n",
            "Epoch 15/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.3285"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 161s 198ms/step - loss: 0.0629 - accuracy: 0.3285\n",
            "Epoch 16/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.3321"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 159s 196ms/step - loss: 0.0627 - accuracy: 0.3321\n",
            "Epoch 17/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.3418"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 162s 199ms/step - loss: 0.0621 - accuracy: 0.3418\n",
            "Epoch 18/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.3469"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 161s 198ms/step - loss: 0.0619 - accuracy: 0.3469\n",
            "Epoch 19/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.3543"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 160s 196ms/step - loss: 0.0615 - accuracy: 0.3543\n",
            "Epoch 20/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.3631"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 163s 200ms/step - loss: 0.0610 - accuracy: 0.3631\n",
            "Epoch 21/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.3693"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 160s 197ms/step - loss: 0.0606 - accuracy: 0.3693\n",
            "Epoch 22/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.3775"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 162s 199ms/step - loss: 0.0602 - accuracy: 0.3775\n",
            "Epoch 23/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.3867"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 162s 199ms/step - loss: 0.0597 - accuracy: 0.3867\n",
            "Epoch 24/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.3956"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 159s 195ms/step - loss: 0.0593 - accuracy: 0.3956\n",
            "Epoch 25/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.3979"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 161s 197ms/step - loss: 0.0591 - accuracy: 0.3979\n",
            "Epoch 26/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.4022"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 159s 196ms/step - loss: 0.0585 - accuracy: 0.4022\n",
            "Epoch 27/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.4112"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 162s 199ms/step - loss: 0.0582 - accuracy: 0.4112\n",
            "Epoch 28/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.4124"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 163s 200ms/step - loss: 0.0580 - accuracy: 0.4124\n",
            "Epoch 29/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.4252"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 165s 202ms/step - loss: 0.0573 - accuracy: 0.4252\n",
            "Epoch 30/30\n",
            "814/814 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.4278"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r814/814 [==============================] - 161s 198ms/step - loss: 0.0571 - accuracy: 0.4278\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TunoK-aWTHfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-47684e6TH-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "44y1p57wTIBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LVX-mA6YTIDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7d1ec8-vTIHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VGG_Model_.summary"
      ],
      "metadata": {
        "id": "4IpYo485hbkL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "b3ad4ae0-3a81-4271-97f7-1d550b5ac571"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9ae84d5ecc60>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mVGG_Model_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'VGG_Model_' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C5S8p0UNhbUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print('VGG_Model Training Completed \\n\\n\\n')\n",
        "# VGG_Model.save('5batch_age_model_VGG16_.h5')  # creates a HDF5 file '5batch_age_model_VGG16_.h5'\n",
        "    "
      ],
      "metadata": {
        "id": "FT4kgtIoODUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XIzjOAhvhbgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uwSCGYoKODEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model_Results = Model.evaluate(xTest,yTest)\n",
        "# print(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\n",
        "# print(\"ACCURACY:  \" + \"%.2f\" % Model_Results[1])"
      ],
      "metadata": {
        "id": "jPJNmhZ0F53h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PzyWtn7pF56n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kYFeeSChF59W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NQziH-sFF6AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dMiUQAlwF6DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AEaFigJKF6Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dxP0XleqF6Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dq1Sxhu_F6Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jz2IlsqQF6On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wl07cjf-F6R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Btc87BLtF6Vh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}